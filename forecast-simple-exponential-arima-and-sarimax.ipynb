{"cells":[{"metadata":{"_uuid":"fd3b6c6d8e51b406c4be5b361e24c0f3c7e5d2b4"},"cell_type":"markdown","source":"## Table of Contents:\n1.  Understanding Time Series\n2. Import libraries and  loading the data\n3. Dataset Structure and Content\n4.  Feature Extraction\n5. EDA - Plots (trend? seasonality?)\n6. Simple models: Average, Naive\n7. Exponential models:Holt,  Holt Winters\n8.  ARIMA\n9. SARIMAX"},{"metadata":{"_uuid":"4e723c4048dbf5c1cf1edc6c408ec066decdf4ad"},"cell_type":"markdown","source":"## 1. Introduction to Time Series\n<b style=\"color:green\">Time Series is generally data which is collected over time and is dependent on it.</b>\n\n**Formal definition of Time Series:**\n\nA series of data points collected in time order is known as a time series. Most of business houses work on time series data to analyze sales number for the next year, website traffic, count of traffic, number of calls received, etc. Data of a time series can be used for forecasting.\n\n<b style=\"color:red\">Not every data collected with respect to time represents a time series.</b>\n\nSome of the examples of time series are:\n* Stock Price :\n* Passenger Count of an airlines :\n* Temperature over time :\n* Number of visitors in a hotel"},{"metadata":{"_uuid":"40376694d945444d0324571a0b2f0f5976a2eab0"},"cell_type":"markdown","source":"### Components of a Time Series\n**1. Trend :** Trend is a general direction in which something is developing or changing.\n\n**2. Seasonality :** The pattern is repeating at regular time interval which is known as the seasonality. Any predictable change or pattern in a time series that recurs or repeats over a specific time period can be said to be seasonality.\n"},{"metadata":{"_uuid":"a5d8f240884ad4d30e05e4159567ae05ed61fb2e"},"cell_type":"markdown","source":"## 2. Import libraries and  loading the data"},{"metadata":{"trusted":true,"_uuid":"3e9eb4c5836f5d47f31871540b50abd33c60b30f"},"cell_type":"code","source":"import pandas as pd          \nimport numpy as np          # For mathematical calculations\nimport matplotlib.pyplot as plt  # For plotting graphs\nfrom datetime import datetime    # To access datetime\nfrom pandas import Series        # To work on series\n%matplotlib inline\nimport warnings                   # To ignore the warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"497539ad5ce7a9a16b8527dddd9efe3d46ea09a2"},"cell_type":"code","source":"# Now let’s read the data\ncandies=pd.read_csv(\"../input/candy_production.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38fbcb42834d059deae85005738421efce3242bd"},"cell_type":"markdown","source":"Let’s make a copy of data so that even if we do changes in these dataset we do not lose the original dataset."},{"metadata":{"trusted":true,"_uuid":"21f7d315c840cd17f0ce5e5ed0336fe605b373ae"},"cell_type":"code","source":"candies_original=candies.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5221c7474fc11e1fe447a25e77bf62906547a411"},"cell_type":"markdown","source":"## 3. Dataset Structure and Content"},{"metadata":{"_uuid":"600fc5605b49d4251a6868ebe1e3c4bcedfbefa0"},"cell_type":"markdown","source":"let’s have a look at the features in the dataset."},{"metadata":{"trusted":true,"_uuid":"f245ee3b770556fe5ff22d7399096fadad075608"},"cell_type":"code","source":"candies.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43d92d971e61dc06a793f4b20511ade21df16d4c"},"cell_type":"markdown","source":"Let’s look at the data types of each feature."},{"metadata":{"trusted":true,"_uuid":"c4dac2afd549a793ce92cd314e7d1ae0edab45a4"},"cell_type":"code","source":"candies.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d1020f3eb3dbf42ead54fe67bb7d2fdb23560d9"},"cell_type":"markdown","source":"See the shape of the dataset."},{"metadata":{"trusted":true,"_uuid":"354f1139e4b35f290913267e50ba1a71476bc3c9"},"cell_type":"code","source":"candies.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ff67bc5a0e568d5e1f3a644e029b8f8732d3f8f"},"cell_type":"code","source":"candies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18b3b465ba9f07b40ed81621898923c453b616d1"},"cell_type":"code","source":"candies.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e05de52f799774e1ed978ad994069cc1cd4a1cd"},"cell_type":"markdown","source":"## 4.  Feature Extraction"},{"metadata":{"trusted":true,"_uuid":"74dab44bbaf92e89cff8decbc99b1790884a7dcf"},"cell_type":"code","source":"candies['observation_date'] = pd.to_datetime(candies.observation_date,format='%Y-%m-%d')  \ncandies_original['observation_date'] = pd.to_datetime(candies_original.observation_date,format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3712fd3a9485802d8d1e434dfd3645ec7c8bd1e"},"cell_type":"code","source":"#  let’s extract the year, month and day from the observation_date\nfor i in (candies,candies_original):\n    i['year']=i.observation_date.dt.year \n    i['month']=i.observation_date.dt.month \n    i['day']=i.observation_date.dt.day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e00e5fd0e11643642552e4b860da9b1d7c52d57"},"cell_type":"code","source":"candies.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2df4cbe927450af82bc89e06314b230da76b63af"},"cell_type":"markdown","source":"## 5. EDA - Plots (trend? seasonality?)"},{"metadata":{"trusted":true,"_uuid":"660c84b0d3b49a352ec1001a4153bce36740ba0c"},"cell_type":"code","source":"candies.index = candies['observation_date'] # indexing the Datetime to get the time period on the x-axis.\nts = candies['IPG3113N']\nplt.figure(figsize=(16,8))\nplt.plot(ts, label='% Candy Production')\nplt.title('Candy Production')\nplt.xlabel(\"Time(year)\")\nplt.ylabel(\"% Candy Production\")\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cab0969016b85d28ce4cb8d50bf6e0611ca2cbe1"},"cell_type":"code","source":"# let’s look at yearly production count.\nplt.figure(figsize=(16,8))\ncandies.groupby('year')['IPG3113N'].mean().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e06658efe894ff2a1ccefe502ab7a3f2565c8e0"},"cell_type":"code","source":"# let’s look at monthly production count.\nplt.figure(figsize=(16,8))\ncandies.groupby('month')['IPG3113N'].mean().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5138cd7e5c547bc5c9f3f82b3db27376830fe2fc"},"cell_type":"code","source":"# Let’s look at the monthly mean of each year separately.\n\ntemp=candies.groupby(['year','month'])['IPG3113N'].mean()\ntemp.plot(figsize=(15,5), title= 'production Count(Monthwise)', fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e311268ffa4c3d7ffc4cab751533b62a3cfc205c"},"cell_type":"markdown","source":"### Splitting the data into training and validation part"},{"metadata":{"trusted":true,"_uuid":"19ef051415bf4ab98d45bc51376d7062799bbd81"},"cell_type":"code","source":"train=candies.ix[:'2011-10-01']\nvalid=candies.ix['2011-11-01':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afef4ec8539ec79bd51066729a4c201f59707d48"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"462022f0b08e487ed97fad583da4eb38e10e820a","trusted":true},"cell_type":"code","source":"train.IPG3113N.plot(figsize=(15,8), title= 'Candy Production', fontsize=14, label='train')\nvalid.IPG3113N.plot(figsize=(15,8), title= 'Candy Production', fontsize=14, label='valid')\nplt.xlabel(\"observation_date\")\nplt.ylabel(\"production count\")\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0022af641803816f4013ed8661feaee5904823b"},"cell_type":"markdown","source":"## 6. Simple models: Naive,Moving Average"},{"metadata":{"_uuid":"e5712d9a778043f86177d89b1d718233d6fe51b3"},"cell_type":"markdown","source":"### Naive"},{"metadata":{"trusted":true,"_uuid":"7d2f8dc8ff801af52f7587058f5a50db2f538877"},"cell_type":"code","source":"# predictions using naive approach for the validation set.\ndd= np.asarray(train['IPG3113N'])\ny_hat = valid.copy()\ny_hat['naive'] = dd[len(dd)-1]\nplt.figure(figsize=(12,8))\nplt.plot(train.index, train['IPG3113N'], label='Train')\nplt.plot(valid.index,valid['IPG3113N'], label='Valid')\nplt.plot(y_hat.index,y_hat['naive'], label='Naive Forecast')\nplt.legend(loc='best')\nplt.title(\"Naive Forecast\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d29a99302913152682bf542985dab2720de74562"},"cell_type":"code","source":"# RMSE(Root Mean Square Error) to check the accuracy of our model on validation data set.\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrms = sqrt(mean_squared_error(valid['IPG3113N'], y_hat.naive))\nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f71c57b3c505b06586c6e73b0b14099479b709d5"},"cell_type":"markdown","source":"### Moving Average"},{"metadata":{"trusted":true,"_uuid":"3eb84c40bf5f0ffca7e347217a934b47b4e9a233"},"cell_type":"code","source":"# last 5 observations.\ny_hat_avg = valid.copy()\ny_hat_avg['moving_avg_forecast'] = train['IPG3113N'].rolling(5).mean().iloc[-1] # average of last 5 observations.\nplt.figure(figsize=(15,5)) \nplt.plot(train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 5 observations')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c295827721610bb06b25b48029c2506c82b97dc0"},"cell_type":"code","source":"# last 7 observations.\ny_hat_avg = valid.copy()\ny_hat_avg['moving_avg_forecast'] = train['IPG3113N'].rolling(7).mean().iloc[-1] # average of last 7 observations.\nplt.figure(figsize=(15,5)) \nplt.plot(train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 7 observations')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd8006140aab42f8d5b02bfd35d881dea8fbfc82"},"cell_type":"code","source":"# last 50 observations.\ny_hat_avg = valid.copy()\ny_hat_avg['moving_avg_forecast'] = train['IPG3113N'].rolling(50).mean().iloc[-1] # average of last 50 observations.\nplt.figure(figsize=(15,5)) \nplt.plot(train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 50 observations')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a86782d728d10e3f88c1aeb7ac1cd1d0f0fa27d2"},"cell_type":"code","source":"rms = sqrt(mean_squared_error(valid['IPG3113N'], y_hat_avg.moving_avg_forecast))\nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db4cb20f8d8daeb22980cf3e9715f4b9c9617a83"},"cell_type":"markdown","source":"#### Considering validate set,  the Moving Average method showed better performance at some important metrics like RMSE and MAPE"},{"metadata":{"_uuid":"dc86058eb074be6dda44673d85921ccd58ac3fcf"},"cell_type":"markdown","source":"## 7. Exponential models: Ses, Holt,  Holt Winters"},{"metadata":{"_uuid":"aa5a999e0b699dc06841e84e77c00897ce064fbc"},"cell_type":"markdown","source":" ### Simple Exponential Smoothing"},{"metadata":{"trusted":true,"_uuid":"a52aaf763816c2887ab5494c6d1e599da6b7ca83"},"cell_type":"code","source":"from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\ny_hat_ex = valid.copy()\nfit2 = SimpleExpSmoothing(np.asarray(train['IPG3113N'])).fit(smoothing_level=0.6,optimized=False)\ny_hat_ex['SES'] = fit2.forecast(len(valid))\nplt.figure(figsize=(16,8))\nplt.plot(train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_ex['SES'], label='SES')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0c37ea3d09a561dd5cb8ad31ecf78b2353c6847"},"cell_type":"code","source":"rms = sqrt(mean_squared_error(valid['IPG3113N'], y_hat_ex['SES']))\nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"497747578e7dba959b67bb3694151342b74b3801"},"cell_type":"markdown","source":" ### Holt’s Linear Trend Model"},{"metadata":{"trusted":true,"_uuid":"abd49bedf3883375c8ea68eaaa363c5351cafe7a"},"cell_type":"code","source":"import statsmodels.api as sm\nsm.tsa.seasonal_decompose(train['IPG3113N']).plot()\nresult = sm.tsa.stattools.adfuller(train['IPG3113N'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"437772e794c3e8348906a6741f8dbbd5d2b221e1"},"cell_type":"code","source":"y_hat_ex = valid.copy()\n\nfit1 = Holt(np.asarray(train['IPG3113N'])).fit(smoothing_level = 0.3,smoothing_slope = 0.1)\ny_hat_ex['Holt_linear'] = fit1.forecast(len(valid))\n\nplt.figure(figsize=(16,8))\nplt.plot(train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_ex['Holt_linear'], label='Holt_linear')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e746f49b4d633e2b5c0866c170241fd39f9f9c9"},"cell_type":"code","source":"rms = sqrt(mean_squared_error(valid['IPG3113N'], y_hat_ex.Holt_linear))\nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d710a140ac234b3b126fba472652a8e4df87da01"},"cell_type":"markdown","source":"### Holt’s Winter method"},{"metadata":{"trusted":true,"_uuid":"6a1118027994a4b19a24d4d1f50676caf5de6749"},"cell_type":"code","source":"y_hat_win = valid.copy()\nfit1 = ExponentialSmoothing(np.asarray(train['IPG3113N']) ,seasonal_periods=25 ,trend='add', seasonal='add',).fit()\ny_hat_win['Holt_Winter'] = fit1.forecast(len(valid))\nplt.figure(figsize=(16,8))\nplt.plot( train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_win['Holt_Winter'], label='Holt_Winter')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd61fe0c8dcb84a995d4ef786f9d6944de4c3d03"},"cell_type":"code","source":"rms = sqrt(mean_squared_error(valid['IPG3113N'], y_hat_win.Holt_Winter))\nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b1ab8406112cab6199f2b10d9a4257e363108af"},"cell_type":"markdown","source":"## 6.  ARIMA\nAs our time series is non stationary, we have to apply differencing to reduce possibles trend and seasonality."},{"metadata":{"trusted":true,"_uuid":"2bee18d521cc1ebbde0d116625e64cb8fece43b0"},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries):\n    \n    #Determing rolling statistics\n    rolmean = timeseries.rolling(24).mean()\n    rolstd = timeseries.rolling(24).std()\n    \n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"058cda084c5bc690ca71f7d286a196426fd121ae"},"cell_type":"code","source":"plt.figure(figsize=(16,8))\ntest_stationarity(candies_original['IPG3113N'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e80028ca7b61c239f306833d7bf027dbc9a35281"},"cell_type":"code","source":"train_log = np.log(train['IPG3113N'])\nvalid_log = np.log(valid['IPG3113N'])\n\nmoving_avg = train_log.rolling(24).mean()\nplt.figure(figsize=(16,8))\nplt.plot(train_log)\nplt.plot(moving_avg, color = 'red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3621370b6e2397882e59e2eefc7d1552e8db8eb0"},"cell_type":"code","source":"train_log_moving_avg_diff = train_log - moving_avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"771a4ec007c34a11a6b1a464226d5545469ab806"},"cell_type":"code","source":"train_log_moving_avg_diff.dropna(inplace = True)\nplt.figure(figsize=(16,8))\ntest_stationarity(train_log_moving_avg_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4d538439f497165a9dd84307ff9b0c81f7282ea"},"cell_type":"code","source":"train_log_diff = train_log - train_log.shift(1)\nplt.figure(figsize=(16,8))\ntest_stationarity(train_log_diff.dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ea6b7ec1df182099b52574d5a99eccd573907c5"},"cell_type":"markdown","source":"### Removing Seasonality"},{"metadata":{"trusted":true,"_uuid":"697fff56bfbc10b374b6d8207f4c06ad17246b3a"},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(pd.DataFrame(train_log).IPG3113N.values, freq = 24)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.figure(figsize=(16,8))\nplt.subplot(411)\nplt.plot(train_log, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"545ccc040f18e5444aaadae3f67b2b7bd457710c"},"cell_type":"code","source":"# Let’s check stationarity of residuals.\n\ntrain_log_decompose = pd.DataFrame(residual)\ntrain_log_decompose['date'] = train_log.index\ntrain_log_decompose.set_index('date', inplace = True)\ntrain_log_decompose.dropna(inplace=True)\nplt.figure(figsize=(16,8))\ntest_stationarity(train_log_decompose[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d4c3666c83791e5c732fd617e992430583be4d4"},"cell_type":"markdown","source":"Forecasting the time series using ARIMA\n\n* First of all we will fit the ARIMA model on our time series for that we have to find the optimized values for the p,d,q parameters.\n\n* To find the optimized values of these parameters, we will use ACF(Autocorrelation Function) and PACF(Partial Autocorrelation Function) graph.\n\n* ACF is a measure of the correlation between the TimeSeries with a lagged version of itself.\n\n* PACF measures the correlation between the TimeSeries with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons.\n"},{"metadata":{"_uuid":"7efd4b43a4eedcf961d39e1e4281a88de11bc0d5","trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\nlag_acf = acf(train_log_diff.dropna(), nlags=25)\nlag_pacf = pacf(train_log_diff.dropna(), nlags=25, method='ols')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8302aed23fc3afdd66d6a9972fdb18afb209fd19"},"cell_type":"code","source":"# ACF plot\nplt.figure(figsize=(16,8))\nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3713f424ae09d6dc0bf666c1aa758d61c7c1035d"},"cell_type":"code","source":"# PACF plot\nplt.figure(figsize=(16,8))\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.title('Partial Autocorrelation Function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41043024ec6b3f8e78fdb89505c5d0fe196e8522"},"cell_type":"markdown","source":"### AR model\n\nThe autoregressive model specifies that the output variable depends linearly on its own previous values.\n"},{"metadata":{"trusted":true,"_uuid":"4e511d5277ad10eb9f3566063ad6edadddb18f32"},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nmodel = ARIMA(train_log, order=(2, 1, 0))  # here the q value is zero since it is just the AR model\nresults_AR = model.fit(disp=-1)  \nplt.figure(figsize=(16,8))\nplt.plot(train_log_diff.dropna(), label='original')\nplt.plot(results_AR.fittedvalues, color='red', label='predictions')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78ea84580bc8780ff5a6ec451bf7194995eb24bf"},"cell_type":"code","source":"# First step would be to store the predicted results as a separate series and observe it.\nAR_predict=results_AR.predict(start=\"2011-11-01\", end=\"2017-08-01\")\nAR_predict=AR_predict.cumsum().shift().fillna(0)\nAR_predict1=pd.Series(np.ones(valid.shape[0]) * np.log(valid['IPG3113N'])[0], index = valid.index)\nAR_predict1=AR_predict1.add(AR_predict,fill_value=0)\nAR_predict = np.exp(AR_predict1)\n\nplt.figure(figsize=(16,8))\nplt.plot(valid['IPG3113N'], label = \"Valid\")\nplt.plot(AR_predict, color = 'red', label = \"Predict\")\nplt.legend(loc= 'best')\nplt.title('RMSE: %.4f'% (np.sqrt(np.dot(AR_predict, valid['IPG3113N']))/valid.shape[0]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54b28f667f9f8879762d8632943d409d415ccf72"},"cell_type":"markdown","source":"### MA model\n\nThe moving-average model specifies that the output variable depends linearly on the current and various past values of a stochastic (imperfectly predictable) term.\n"},{"metadata":{"trusted":true,"_uuid":"27a4254bcef4bc7d454d2a8abe2f58613d05bd04"},"cell_type":"code","source":"\nmodel = ARIMA(train_log, order=(0, 1, 2))  # here the p value is zero since it is just the MA model\nresults_MA = model.fit(disp=-1)\nplt.figure(figsize=(16,8))\nplt.plot(train_log_diff.dropna(), label='original')\nplt.plot(results_MA.fittedvalues, color='red', label='prediction')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb4049533488827e0e245cbc15ad4c675d9fa3ef"},"cell_type":"code","source":"MA_predict=results_MA.predict(start=\"2011-11-01\", end=\"2017-08-01\")\nMA_predict=MA_predict.cumsum().shift().fillna(0)\nMA_predict1=pd.Series(np.ones(valid.shape[0]) * np.log(valid['IPG3113N'])[0], index = valid.index)\nMA_predict1=MA_predict1.add(MA_predict,fill_value=0)\nMA_predict = np.exp(MA_predict1)\n\nplt.figure(figsize=(16,8))\nplt.plot(valid['IPG3113N'], label = \"Valid\")\nplt.plot(MA_predict, color = 'red', label = \"Predict\")\nplt.legend(loc= 'best')\nplt.title('RMSE: %.4f'% (np.sqrt(np.dot(MA_predict, valid['IPG3113N']))/valid.shape[0]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6c1c14c8d812ac676ff8b5587a349b4a4446c3e"},"cell_type":"markdown","source":"### Combined model"},{"metadata":{"trusted":true,"_uuid":"9daa8ef9f496fff3f08b6cf895890a09fea7e111"},"cell_type":"code","source":"model = ARIMA(train_log, order=(2, 1, 2))  \nresults_ARIMA = model.fit(disp=-1)  \n\nplt.figure(figsize=(16,8))\nplt.plot(train_log_diff.dropna(),  label='original')\nplt.plot(results_ARIMA.fittedvalues, color='red', label='predicted')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"261a449434e8f079c1011e96b4e36f02cc7c5e16"},"cell_type":"code","source":"# Let’s define a function which can be used to change the scale of the model to the original scale.\n\ndef check_prediction_diff(predict_diff, given_set):\n    predict_diff= predict_diff.cumsum().shift().fillna(0)\n    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['IPG3113N'])[0], index = given_set.index)\n    predict_log = predict_base.add(predict_diff,fill_value=0)\n    predict = np.exp(predict_log)\n    \n    plt.figure(figsize=(16,8))\n    plt.plot(given_set['IPG3113N'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['IPG3113N']))/given_set.shape[0]))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"442022dfbf2ae980e3aa8b7ed612efaff617f74d"},"cell_type":"code","source":"def check_prediction_log(predict_log, given_set):\n    predict = np.exp(predict_log)\n    \n    plt.figure(figsize=(16,8))\n    plt.plot(given_set['IPG3113N'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['IPG3113N']))/given_set.shape[0]))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0bafbc8a606ce7aca575d189a8e08b7ff38121d"},"cell_type":"markdown","source":"Let’s predict the values for validation set."},{"metadata":{"trusted":true,"_uuid":"856f3b8ce8f95eb4f78da85f242b8ec8ab486e21"},"cell_type":"code","source":"ARIMA_predict_diff=results_ARIMA.predict(start=\"2011-11-01\", end=\"2017-08-01\")\n\ncheck_prediction_diff(ARIMA_predict_diff, valid)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30e4cead912e75231a40d749245d0de758372839"},"cell_type":"markdown","source":"## SARIMAX\n\nSARIMAX model takes into account the seasonality of the time series. So we will build a SARIMAX model on the time series.\n"},{"metadata":{"trusted":true,"_uuid":"0a2eef7041c9d1200fdc53ea7f4ecd73aab12234"},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\ny_hat_avg = valid.copy()\nfit1 = SARIMAX(train['IPG3113N'], order=(2, 1, 4),seasonal_order=(0,1,1,7),enforce_stationarity=False,enforce_invertibility=False).fit()\ny_hat_ex['SARIMA'] = fit1.predict(start=\"2011-11-01\", end=\"2017-08-01\", dynamic=True)\nplt.figure(figsize=(16,8))\nplt.plot( train['IPG3113N'], label='Train')\nplt.plot(valid['IPG3113N'], label='Valid')\nplt.plot(y_hat_ex['SARIMA'], label='SARIMA')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e0aee60dd8d478d1c5b4cab1fd55d50a1dafc8a"},"cell_type":"code","source":"# Let’s check the rmse value for the validation part.\n\nrms = sqrt(mean_squared_error(valid['IPG3113N'], y_hat_ex.SARIMA))\nprint(rms)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}